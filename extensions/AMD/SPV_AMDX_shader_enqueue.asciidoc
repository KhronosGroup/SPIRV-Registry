SPV_AMDX_shader_enqueue
======================

Name Strings
------------

SPV_AMDX_shader_enqueue

Contact
-------

See *Issues* list in the Khronos SPIRV-Headers repository:
https://github.com/KhronosGroup/SPIRV-Headers

Provisional
-----------

*This extension is _provisional_ and should: not be used in production applications.
The functionality may change in ways that break backwards compatibility between
revisions, and before final release.*

Contributors
------------

- Tobias Hector, AMD
- Matthäus Chajdas, AMD
- Nicolai Hähnle, AMD
- Junda Liu, AMD
- Maciej Jesionowski, AMD
- Daniel Brown, AMD
- Stuart Smith, AMD

Notice
------

Copyright (c) 2024 The Khronos Group Inc. Copyright terms at
http://www.khronos.org/registry/speccopyright.html

Status
------

Provisional.

Version
-------

[width="40%",cols="25,25"]
|========================================
| Last Modified Date | 2024-07-26
| Revision           | 2
|========================================

Dependencies
------------

This extension is written against the Unified SPIR-V Specification,
Version 1.6, Revision 1.

This extension requires SPIR-V 1.4.

Overview
--------

This extension adds the ability for developers to enqueue compute
and mesh shader workgroups from compute shaders.

Extension Name
--------------

To use this extension within a SPIR-V module, the following
*OpExtension* must be present in the module:

----
OpExtension "SPV_AMDX_shader_enqueue"
----

=== Capabilities

Modify Section 3.31, "Capability", adding this row to the table:

[cols="1,10,8",options="header"]
|====
2+^.^| Capability | Enabling Capabilities
| 5067 | *ShaderEnqueueAMDX* +
Uses shader enqueue capabilities | *Shader*
|====

=== Storage Class

Modify Section 3.7, "Storage Class", adding this row to the table:

[cols="1,10,8",options="header"]
|====
2+^.^| Storage Class | Enabling Capabilities
| 5068 | *NodePayloadAMDX* +
Storage for Node Payloads. +
 +
Variables declared with *OpVariable* in the *GLCompute* execution model with the *CoalescingAMDX* execution mode are visible across all invocations within a workgroup; and other variables declared with *OpVariable* in this storage class are visible across all invocations within a node dispatch.
Variables declared with this storage class are readable and writable, and must not have initializers. +
 +
Pointers to this storage class are also used to point to payloads allocated and enqueued for other nodes.
| *ShaderEnqueueAMDX*
|====

== Execution Modes

Modify Section 3.6, "Execution Mode", adding the following rows to the table:

[cols="1,10,3,3,3,8",options="header"]
|====
2+^.^| Execution Mode 3+| Extra Operands | Enabling Capabilities
| 5069 | *CoalescingAMDX* +
Indicates that a GLCompute shader has coalescing semantics. (GLCompute only) +
 +
Must not be declared alongside *StaticNumWorkgroupsAMDX* or *MaxNumWorkgroupsAMDX*.
3+|
|*ShaderEnqueueAMDX*
| 5071 | *MaxNodeRecursionAMDX* +
Maximum number of times a node can enqueue payloads for itself.
3+| _<id>_ +
_Number of recursions_
|*ShaderEnqueueAMDX*
| 5070 | *IsApiEntryAMDX* +
Indicates whether the shader can be dispatched directly by the client API or not. (GLCompute and MeshEXT execution models only) +
 +
_Is Entry_ is a scalar Boolean value, with a value of *true* indicating that it can be dispatched from the API, and *false* indicating that it cannot.
If not specified, defaults to *true*. +
 +
Must be set to *false* if *SharesInputWithAMDX* is specified.
3+| _<id>_ +
_Is Entry_
|*ShaderEnqueueAMDX*
| 5072 | *StaticNumWorkgroupsAMDX* +
Statically declare the number of workgroups dispatched for this shader, instead of obeying an API- or payload-specified value. (GLCompute and MeshEXT only) +
 +
Must not be declared alongside *CoalescingAMDX* or *MaxNumWorkgroupsAMDX*.
| _<id>_ +
_x size_
| _<id>_ +
_y size_
| _<id>_ +
_z size_
|*ShaderEnqueueAMDX*
| 5077 | *MaxNumWorkgroupsAMDX* +
Declare the maximum number of workgroups dispatched for this shader. Dispatches must not exceed this value (GLCompute and MeshEXT only) +
 +
Must not be declared alongside *CoalescingAMDX* or *StaticNumWorkgroupsAMDX*.
| _<id>_ +
_x size_
| _<id>_ +
_y size_
| _<id>_ +
_z size_
|*ShaderEnqueueAMDX*
| 5073 | *ShaderIndexAMDX* +
Declare the node index for this shader. (GLCompute and MeshEXT only) 3+| _<id>_ +
_Shader Index_
|*ShaderEnqueueAMDX*
| 5102 | *SharesInputWithAMDX* +
Declare that this shader is paired with another node, such that it will be dispatched with the same input payload when the identified node is dispatched. +
_Node Name_ and _Shader Index_ indicate the node that the input will be shared with. +
 +
_Node Name_ must be an *OpConstantStringAMDX* or *OpSpecConstantStringAMDX* instruction.
| <id> +
_Node Name_
| _<id>_ +
_Shader Index_
|
|*ShaderEnqueueAMDX*
|====

== Decorations

Modify Section 3.20, "Decoration", adding the following row to the table:

[cols="1,10,3,4",options="header"]
|====
2+^.^| Decoration | Extra Operands | Enabling Capabilities
| 5020 | *NodeMaxPayloadsAMDX* +
Must only be used to decorate an *OpTypeNodePayloadArrayAMDX*. +
 +
*OpTypeNodePayloadArrayAMDX* must have this decoration.
The operand indicates the maximum number of payloads that can be in the array, and the maximum number of payloads that can be enqueued with this type.
| _<id>_ +
_Max number of payloads_
|*ShaderEnqueueAMDX*

| 5019 | *NodeSharesPayloadLimitsWithAMDX* +
Decorates an *OpTypeNodePayloadArrayAMDX* declaration to indicate that payloads of this type share output resources with _Payload Type_ when allocated. +
 +
Without the decoration, each types's resources are separately allocated against the output limits; by using the decoration only the limits of _Payload Type_ are considered.
Applications must still ensure that at runtime the actual usage does not exceed these limits, as this decoration only modifies static validation. +
 +
Must only be used to decorate an *OpTypeNodePayloadArrayAMDX* declaration,
_Payload Type_ must be a different *OpTypeNodePayloadArrayAMDX* declaration, and
_Payload Type_ must not be itself decorated with *NodeSharesPayloadLimitsWithAMDX*. +
 +
It is only necessary to decorate one *OpTypeNodePayloadArrayAMDX* declaration to indicate sharing between two node outputs.
Multiple variables can be decorated with the same _Payload Type_ to indicate sharing across multiple node outputs.
| _<id>_ +
_Payload Type_
|*ShaderEnqueueAMDX*

| 5091 | *PayloadNodeNameAMDX* +
Decorates an *OpTypeNodePayloadArrayAMDX* declaration to indicate that the payloads in the array
will be enqueued for the shader with _Node Name_. +
 +
Must only be used to decorate an *OpTypeNodePayloadArrayAMDX* declaration. +
 +
_Node Name_ must be an *OpConstantStringAMDX* or *OpSpecConstantStringAMDX* instruction.
| _<id>_ +
_Node Name_
|*ShaderEnqueueAMDX*

| 5098 | *PayloadNodeBaseIndexAMDX* +
Decorates an *OpTypeNodePayloadArrayAMDX* declaration to indicate a base index that
will be added to the _Node Index_ when allocating payloads of this type.
If not specified, it is equivalent to specifying a value of 0. +
 +
Must only be used to decorate an *OpTypeNodePayloadArrayAMDX* declaration.
| _<id>_ +
_Base Index_
|*ShaderEnqueueAMDX*

| 5099 | *PayloadNodeSparseArrayAMDX* +
Decorates an *OpTypeNodePayloadArrayAMDX* declaration to indicate that nodes at some node indexes may not exist in the execution graph pipeline and cannot be used to allocate payloads. +
 +
If not specified, all node indexes between 0 and the *PayloadNodeArraySizeAMDX* value must be valid nodes in the graph. +
 +
Must only be used to decorate an *OpTypeNodePayloadArrayAMDX* declaration.
|
|*ShaderEnqueueAMDX*

| 5100 | *PayloadNodeArraySizeAMDX* +
Decorates an *OpTypeNodePayloadArrayAMDX* declaration to indicate the maximum node index that can be used when allocating payloads of this type, including the base index offset in *PayloadNodeBaseIndexAMDX* decoration (if present).
If not specified, the node array is considered unbounded. +
 +
Must only be used to decorate an *OpTypeNodePayloadArrayAMDX* declaration. +
 +
If *PayloadNodeSparseArrayAMDX* is not set to *true* for a type initialized by *OpAllocateNodePayloadsAMDX*, this must be specified.
| _<id>_ +
_Array Size_
|*ShaderEnqueueAMDX*

| 5078 | *TrackFinishWritingAMDX* +
Decorates a structure to indicate that when used as a payload it can be written to and works with the *OpFinishWritingNodePayloadAMDX* instruction. +
 +
Must only be used to decorate a structure type declaration. +
 +
If the payload enqueued for a node is using a structure decorated with this value, the input payload in the *NodePayloadAMDX* storage class in the receiving node must use a structure decorated with it as well.
|
|*ShaderEnqueueAMDX*

| 5105 | *PayloadDispatchIndirectAMDX* +
Indicates the dispatch indirect arguments describing the number of workgroups to dispatch in a payload.
Must only be used with *OpMemberDecorate* to decorate the member of a structure.

Must decorate a structure member with a type of *OpTypeInt* or *OpTypeVector* with two or three components.
The integer type or the type of the vector component must be an *OpTypeInt* with up to 32-bit _Width_ and 0 _Signedness_.
If a single integer is used, the Y and Z dispatch indirect arguments are assumed to be 1.
If a vector of two components is used, the Z dispatch indirect argument is assumed to be 1.
|
|*ShaderEnqueueAMDX*
|====

== Builtins

Modify Section 3.21, "BuiltIn", adding the following row to the table:

[cols="1,10,8",options="header"]
|====
2+^.^| BuiltIn | Enabling Capabilities
| 5021 | *RemainingRecursionLevelsAMDX* +
The number of times this node can still enqueue payloads for itself. +
Is equal to 0 if at the leaf or if the node is not recursive at all.
|*ShaderEnqueueAMDX*
| 5073 | *ShaderIndexAMDX* +
Index assigned to the current shader.
|*ShaderEnqueueAMDX*
|====

== Instructions

Add the following new instructions:

[cols="4*1"]
|======
3+|[[OpConstantStringAMDX]]*OpConstantStringAMDX* +
 +
Declare a new string specialization constant. +
 +
_String_ is the value of the constant. +
 +
Unlike *OpString*, this is a semantically meaningful instruction and cannot be safely removed from a module.
1+|Capability: +
*ShaderEnqueueAMDX*
| 3 + variable | 5103
| _Result <id>_
| _Literal_ +
_String_
|======

[cols="4*1"]
|======
3+|[[OpSpecConstantStringAMDX]]*OpSpecConstantStringAMDX* +
 +
Declare a new string specialization constant. +
 +
_String_ is the default value of the constant. +
 +
Unlike *OpString*, this is a semantically meaningful instruction and cannot be safely removed from a module. +
 +
This instruction can be specialized to become an *OpConstantStringAMDX* instruction. +
 +
See _Specialization_.
1+|Capability: +
*ShaderEnqueueAMDX*
| 3 + variable | 5104
| _Result <id>_
| _Literal_ +
_String_
|======

[cols="4*1",width="100%"]
|=====
3+|[[OpTypeNodePayloadArrayAMDX]]*OpTypeNodePayloadArrayAMDX* +
 +
Declare a new payload array type.  Its length is not known at compile time. +
 +
_Payload Type_ is the type of each payload in the array. +
 +
 See <<OpNodePayloadArrayLengthAMDX,*OpNodePayloadArrayLengthAMDX*>> for getting the length of an array of this type. +
 +
A payload array can be allocated by either *OpAllocateNodePayloadsAMDX* to be enqueued as an output, or via *OpVariable* in the *NodePayloadAMDX* storage class to be consumed as an input. +
 +
Can be dereferenced using an access chain in the same way as *OpTypeRuntimeArray* or *OpTypeArray*.
1+|<<Capability,Capability>>: +
*Shader*
| 3 | 5076
| _Result <id>_
| _<id>_ +
_Payload Type_
|=====

[cols="6*2,4"]
|======
6+|[[OpAllocateNodePayloadsAMDX]]*OpAllocateNodePayloadsAMDX* +
 +
Allocates payloads for a node to be later enqueued via *OpEnqueueNodePayloadsAMDX*. +
 +
_Result Type_ must be an *OpTypePointer* to an *OpTypeNodePayloadArrayAMDX* in the *NodePayloadAMDX* storage class. +
 +
The payloads are allocated for the node identified by the _Node Name_ in the *PayloadNodeNameAMDX* decoration on _Result Type_,
with an index equal to the sum of its *PayloadNodeBaseIndexAMDX* decoration (if present) and _Node Index_.
 +
Payloads are allocated for the _Scope_ indicated by _Visibility_, and are visible to all invocations in that _Scope_. +
 +
_Payload Count_ is the number of payloads to allocate in the resulting array.
 +
Behavior is undefined if _Payload Count_ is greater than the *NodeMaxPayloadsAMDX* decoration on _Result Type_. +
 +
_Payload Count_ and _Node Index_ must be dynamically uniform within the scope identified by _Visibility_. +
 +
_Visibility_ must only be either _Invocation_ or _Workgroup_. +
 +
This instruction must be called in uniform control flow within the same workgroup.
1+|Capability: +
*ShaderEnqueueAMDX*
| 6 | 5074
| _<id>_ +
_Result Type_
| _Result_ _<id>_
| _Scope <id>_ +
_Visibility_
| _<id>_ +
_Payload Count_
| _<id>_ +
_Node Index_
|======

[cols="3,1,1"]
|======
2+|[[OpEnqueueNodePayloadsAMDX]]*OpEnqueueNodePayloadsAMDX* +
 +
Enqueues a previously allocated payload array for execution by its node. +
 +
_Payload Array_ is a pointer to a payload array that was previously allocated by *OpAllocateNodePayloadsAMDX*. +
 +
This instruction must be called in uniform control flow within the workgroup.
1+|Capability: +
*ShaderEnqueueAMDX*
| 2 | 5075
| _<id>_ +
_Payload Array_
|======

[cols="2*1,3*2",width="100%"]
|=====
4+|[[OpNodePayloadArrayLengthAMDX]]*OpNodePayloadArrayLengthAMDX* +
 +
Query the length of a payload array. Must only be used with input payload arrays or allocated output payload arrays. +
 +
_Result_ will be equal to the _Payload Count_ value used to allocate _Payload Array_, or to the number of received payloads if the shader is using *CoalescingAMDX* execution mode. Otherwise, _Result_ will be 1. +
 +
_Result Type_ must be an *OpTypeInt* with 32-bit _Width_ and 0 _Signedness_. +
 +
_Payload Array_ is a pointer to a payload array previously allocated by *OpAllocateNodePayloadsAMDX*, or declared via *OpVariable* in the *NodePayloadAMDX* storage class as an input.
1+|<<Capability,Capability>>: +
*Shader*
| 4 | 5090
| _<id>_ +
_Result Type_
| _Result <id>_
| _<id>_ +
_Payload Array_
|=====

[cols="1,2,2,2,2,2"]
|======
5+|[[OpIsNodePayloadValidAMDX]]*OpIsNodePayloadValidAMDX* +
 +
Check if the node payload identified by the _Node Name_ in the *PayloadNodeNameAMDX* decoration,
with an index equal to the sum of its *PayloadNodeBaseIndexAMDX* decoration (if present) and _Node Index_
can be allocated. +
 +
_Result_ is equal to *OpConstantTrue* if the payload is valid and can be allocated, *OpConstantFalse* otherwise. +
 +
_Result Type_ must be *OpTypeBool*. +
 +
_Payload Type_ must be an *OpTypeNodePayloadArrayAMDX* declaration. +
 +
_NodeIndex_ must be less than the value specified by the *PayloadNodeArraySizeAMDX* decoration if specified.
1+|Capability: +
*ShaderEnqueueAMDX*
| 5 | 5101
| _<id>_ +
_Result Type_
| _Result_ _<id>_
| _<id>_ +
_Payload Type_
| _<id>_ +
_Node Index_
|======

[cols="3,1,1,1,1"]
|======
4+|[[OpFinishWritingNodePayloadAMDX]]*OpFinishWritingNodePayloadAMDX* +
 +
Optionally indicates that all writes to the input payload by the current workgroup have completed. +
 +
_Result_ is equal to *OpConstantTrue* if all workgroups that can access this payload have called this function. +
 +
Must not be called if the shader is using *CoalescingAMDX* execution mode,
or if the shader was dispatched with a `vkCmdDispatchGraph*` client API command,
rather than enqueued from another shader. +
 +
Must not be called if the input payload is not decorated with *TrackFinishWritingAMDX*. +
 +
_Result Type_ must be *OpTypeBool*. +
 +
_Payload_ must be the result of an *OpVariable* in the *NodePayloadAMDX* storage class.
1+|Capability: +
*ShaderEnqueueAMDX*
| 4 | 5078
| _<id>_ +
_Result Type_
| _Result_ _<id>_
| _<id>_ +
_Payload_
|======

=== Validation Rules

In section 2.16, Validation Rules for Shader Capabilities, Add *NodePayloadAMDX* to the list of storage classes where composite variables must be explicitly laid out.


== Issues

- None


== Revision History

[cols="5,15,15,70"]
[grid="rows"]
[options="header"]
|========================================
|Rev|Date|Author|Changes
|1|2023-07-22|Tobias Hector| Initial revision.
|2|2024-07-26|Tobias Hector| Update to better match HLSL
|========================================
